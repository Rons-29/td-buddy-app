# ğŸ—ï¸ Webç‰ˆæœ¬ç•ªç’°å¢ƒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
# TestData Buddy (TD) æœ¬ç•ªç’°å¢ƒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

## ğŸ¯ è¨­è¨ˆæ–¹é‡

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŸå‰‡
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: æ€¥æ¿€ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å¢—åŠ ã«å¯¾å¿œå¯èƒ½
- **å¯ç”¨æ€§**: 99.9%ä»¥ä¸Šã®ç¨¼åƒç‡ã‚’ä¿è¨¼
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
- **ä¿å®ˆæ€§**: é‹ç”¨ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãŒå®¹æ˜“
- **ã‚³ã‚¹ãƒˆåŠ¹ç‡**: æ®µéšçš„ãªã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ãŒå¯èƒ½

**TDã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: ã€Œæœ¬ç•ªç’°å¢ƒã§ã¯ã€å®‰å…¨æ€§ã¨æ€§èƒ½ã‚’æœ€å„ªå…ˆã«è¨­è¨ˆã—ã¾ã—ãŸï¼ã€

## ğŸš€ ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“æ§‹æˆ

### é«˜ãƒ¬ãƒ™ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³
```mermaid
graph TB
    User[ğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼] --> CDN[ğŸŒ CloudFlare CDN]
    CDN --> LB[âš–ï¸ Load Balancer]
    LB --> App1[ğŸ–¥ï¸ App Server 1]
    LB --> App2[ğŸ–¥ï¸ App Server 2]
    LB --> App3[ğŸ–¥ï¸ App Server 3]
    
    App1 --> Cache[ğŸ“¦ Redis Cache]
    App2 --> Cache
    App3 --> Cache
    
    App1 --> DB[(ğŸ—„ï¸ PostgreSQL)]
    App2 --> DB
    App3 --> DB
    
    App1 --> Files[ğŸ“ File Storage]
    App2 --> Files
    App3 --> Files
    
    subgraph "Monitoring & Logging"
        Monitor[ğŸ“Š Monitoring]
        Logs[ğŸ“‹ Logging]
    end
    
    App1 --> Monitor
    App2 --> Monitor  
    App3 --> Monitor
    
    App1 --> Logs
    App2 --> Logs
    App3 --> Logs
    
    subgraph "External Services"
        Claude[ğŸ§  Claude AI]
        Email[ğŸ“§ Email Service]
        Backup[ğŸ’¾ Backup Storage]
    end
    
    App1 --> Claude
    App2 --> Claude
    App3 --> Claude
    
    DB --> Backup
    Files --> Backup
```

## ğŸ› ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
```typescript
// Next.js 14 + React 18
// æœ¬ç•ªæœ€é©åŒ–è¨­å®š

// next.config.js
const nextConfig = {
  output: 'standalone',
  experimental: {
    appDir: true,
  },
  images: {
    domains: ['cdn.td-buddy.com'],
  },
  env: {
    NEXT_PUBLIC_API_URL: process.env.API_URL,
  },
  // ãƒãƒ³ãƒ‰ãƒ«æœ€é©åŒ–
  webpack: (config, { isServer }) => {
    if (!isServer) {
      config.resolve.fallback = {
        fs: false,
        net: false,
        tls: false,
      };
    }
    return config;
  },
  // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼
  async headers() {
    return [
      {
        source: '/(.*)',
        headers: [
          { key: 'X-Frame-Options', value: 'DENY' },
          { key: 'X-Content-Type-Options', value: 'nosniff' },
          { key: 'X-XSS-Protection', value: '1; mode=block' },
          { key: 'Referrer-Policy', value: 'strict-origin-when-cross-origin' },
        ],
      },
    ];
  },
};
```

### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API
```typescript
// Express.js + TypeScript
// é«˜å¯ç”¨æ€§ãƒ»é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š

// æœ¬ç•ªç’°å¢ƒè¨­å®š
const productionConfig = {
  port: process.env.PORT || 3001,
  cors: {
    origin: ['https://td-buddy.com', 'https://www.td-buddy.com'],
    credentials: true,
  },
  rateLimit: {
    windowMs: 15 * 60 * 1000, // 15åˆ†
    max: 100, // ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶é™
    standardHeaders: true,
    legacyHeaders: false,
  },
  helmet: {
    contentSecurityPolicy: {
      directives: {
        defaultSrc: ["'self'"],
        styleSrc: ["'self'", "'unsafe-inline'"],
        scriptSrc: ["'self'"],
        imgSrc: ["'self'", "data:", "https:"],
      },
    },
  },
  database: {
    host: process.env.DB_HOST,
    port: parseInt(process.env.DB_PORT || '5432'),
    database: process.env.DB_NAME,
    username: process.env.DB_USER,
    password: process.env.DB_PASSWORD,
    ssl: {
      rejectUnauthorized: false,
    },
    pool: {
      min: 2,
      max: 20,
      acquire: 30000,
      idle: 10000,
    },
  },
};
```

## ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

### PostgreSQL æœ¬ç•ªæ§‹æˆ
```sql
-- æœ¬ç•ªç’°å¢ƒç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

-- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–è¨­å®š
-- postgresql.confè¨­å®š
shared_buffers = 256MB
effective_cache_size = 1GB
maintenance_work_mem = 64MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1

-- æ¥ç¶šè¨­å®š
max_connections = 100
listen_addresses = '*'
port = 5432

-- ãƒ­ã‚°è¨­å®š
log_destination = 'stderr'
logging_collector = on
log_directory = 'pg_log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_statement = 'mod'
log_min_duration_statement = 1000
```

### ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆï¼ˆæœ¬ç•ªæœ€é©åŒ–ï¼‰
```sql
-- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå°†æ¥ã®èªè¨¼æ©Ÿèƒ½ç”¨ï¼‰
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    display_name VARCHAR(100),
    plan_type VARCHAR(20) DEFAULT 'free',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç”Ÿæˆãƒ‡ãƒ¼ã‚¿å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE generation_history (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    session_id VARCHAR(255),
    data_type VARCHAR(50) NOT NULL,
    parameters JSONB,
    generated_count INTEGER,
    file_path VARCHAR(500),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP + INTERVAL '24 hours')
);

-- ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE usage_statistics (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    date DATE NOT NULL,
    total_generations INTEGER DEFAULT 0,
    unique_users INTEGER DEFAULT 0,
    data_type_breakdown JSONB,
    performance_metrics JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
CREATE INDEX idx_generation_history_user_id ON generation_history(user_id);
CREATE INDEX idx_generation_history_created_at ON generation_history(created_at);
CREATE INDEX idx_generation_history_expires_at ON generation_history(expires_at);
CREATE INDEX idx_usage_statistics_date ON usage_statistics(date);

-- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰
CREATE TABLE generation_history_y2025m01 PARTITION OF generation_history
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
-- æœˆã”ã¨ã«ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ...
```

## ğŸ”§ ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£

### Docker æ§‹æˆ
```dockerfile
# Frontend Dockerfile
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM node:18-alpine AS runner
WORKDIR /app
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs
COPY --from=builder /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs
EXPOSE 3000
ENV PORT 3000
CMD ["node", "server.js"]

# Backend Dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

EXPOSE 3001
USER node
CMD ["npm", "start"]
```

### Docker Composeï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  frontend:
    build:
      context: ./td-buddy-webapp/frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=https://api.td-buddy.com
    restart: unless-stopped
    networks:
      - td-network

  backend:
    build:
      context: ./td-buddy-webapp/backend
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://user:pass@postgres:5432/td_buddy
      - REDIS_URL=redis://redis:6379
      - CLAUDE_API_KEY=${CLAUDE_API_KEY}
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    networks:
      - td-network

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=td_buddy
      - POSTGRES_USER=td_user
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    networks:
      - td-network

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - td-network

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/ssl/certs
    depends_on:
      - frontend
      - backend
    restart: unless-stopped
    networks:
      - td-network

volumes:
  postgres_data:
  redis_data:

networks:
  td-network:
    driver: bridge
```

## âš–ï¸ ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ & ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·

### Nginx è¨­å®š
```nginx
# nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream frontend {
        server frontend:3000;
    }
    
    upstream backend {
        server backend:3001;
    }
    
    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®š
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=web:10m rate=30r/s;
    
    server {
        listen 80;
        server_name td-buddy.com www.td-buddy.com;
        return 301 https://$server_name$request_uri;
    }
    
    server {
        listen 443 ssl http2;
        server_name td-buddy.com www.td-buddy.com;
        
        ssl_certificate /etc/ssl/certs/td-buddy.crt;
        ssl_certificate_key /etc/ssl/certs/td-buddy.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆNext.jsï¼‰
        location / {
            limit_req zone=web burst=20 nodelay;
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # APIï¼ˆExpress.jsï¼‰
        location /api/ {
            limit_req zone=api burst=10 nodelay;
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«
        location /static/ {
            alias /var/www/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}
```

## ğŸ“Š ç›£è¦–ãƒ»ãƒ­ã‚°è¨­å®š

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–
```typescript
// monitoring.ts
import { createPrometheusMetrics } from 'prom-client';

export const metrics = {
  httpRequestDuration: new Histogram({
    name: 'http_request_duration_seconds',
    help: 'HTTP request duration in seconds',
    labelNames: ['method', 'route', 'status'],
  }),
  
  dataGenerationCount: new Counter({
    name: 'data_generation_total',
    help: 'Total number of data generations',
    labelNames: ['type', 'success'],
  }),
  
  activeUsers: new Gauge({
    name: 'active_users',
    help: 'Number of currently active users',
  }),
  
  databaseConnections: new Gauge({
    name: 'database_connections',
    help: 'Number of active database connections',
  }),
};

// ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
app.get('/health', async (req, res) => {
  const health = {
    status: 'healthy',
    timestamp: new Date().toISOString(),
    version: process.env.npm_package_version,
    uptime: process.uptime(),
    database: await checkDatabaseHealth(),
    redis: await checkRedisHealth(),
    claude: await checkClaudeAPIHealth(),
  };
  
  res.json(health);
});
```

### ãƒ­ã‚°è¨­å®š
```typescript
// logger.ts
import winston from 'winston';

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: 'td-buddy-backend' },
  transports: [
    new winston.transports.File({ 
      filename: 'logs/error.log', 
      level: 'error' 
    }),
    new winston.transports.File({ 
      filename: 'logs/combined.log' 
    }),
    new winston.transports.Console({
      format: winston.format.simple()
    })
  ],
});

// æ§‹é€ åŒ–ãƒ­ã‚°
export const logDataGeneration = (data: {
  userId?: string;
  dataType: string;
  count: number;
  duration: number;
  success: boolean;
}) => {
  logger.info('Data generation completed', data);
};
```

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–

### SSL/TLS è¨­å®š
```bash
# SSLè¨¼æ˜æ›¸è¨­å®šï¼ˆLet's Encryptï¼‰
# certbotè¨­å®š
certbot certonly --webroot \
  -w /var/www/certbot \
  -d td-buddy.com \
  -d www.td-buddy.com \
  --email admin@td-buddy.com \
  --agree-tos \
  --non-interactive

# è‡ªå‹•æ›´æ–°è¨­å®š
0 12 * * * /usr/bin/certbot renew --quiet
```

### WAFï¼ˆWeb Application Firewallï¼‰
```nginx
# ModSecurityè¨­å®šä¾‹
SecRuleEngine On
SecDefaultAction "phase:1,log,auditlog,deny,status:403"

# SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
SecRule ARGS "@detectSQLi" \
    "id:1001,phase:2,block,msg:'SQL Injection Attack Detected'"

# XSSå¯¾ç­–
SecRule ARGS "@detectXSS" \
    "id:1002,phase:2,block,msg:'XSS Attack Detected'"

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ¶é™
SecRule REQUEST_HEADERS:Content-Type "^multipart/form-data" \
    "id:1003,phase:1,t:lowercase,chain"
SecRule ARGS_POST "@fileMatch /(\.exe|\.bat|\.cmd|\.sh|\.php)$/i" \
    "block,msg:'Dangerous file extension'"
```

## ğŸ“¦ CDNãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

### CloudFlare è¨­å®š
```javascript
// cloudflare-worker.js
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  const url = new URL(request.url)
  
  // é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·æœŸã‚­ãƒ£ãƒƒã‚·ãƒ¥
  if (url.pathname.startsWith('/static/')) {
    const response = await fetch(request)
    const modifiedResponse = new Response(response.body, {
      status: response.status,
      statusText: response.statusText,
      headers: {
        ...response.headers,
        'Cache-Control': 'public, max-age=31536000',
      },
    })
    return modifiedResponse
  }
  
  // API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®çŸ­æœŸã‚­ãƒ£ãƒƒã‚·ãƒ¥
  if (url.pathname.startsWith('/api/generate/')) {
    const cacheKey = new Request(url.toString(), request)
    const cache = caches.default
    let response = await cache.match(cacheKey)
    
    if (!response) {
      response = await fetch(request)
      if (response.status === 200) {
        const responseToCache = response.clone()
        response.headers.set('Cache-Control', 'public, max-age=300')
        event.waitUntil(cache.put(cacheKey, responseToCache))
      }
    }
    return response
  }
  
  return fetch(request)
}
```

## ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ç½å®³å¾©æ—§

### è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# backup.sh - è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/td-buddy/$TIMESTAMP"
mkdir -p $BACKUP_DIR

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
pg_dump -h postgres -U td_user td_buddy > $BACKUP_DIR/database.sql

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
tar -czf $BACKUP_DIR/files.tar.gz /app/uploads /app/generated

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp -r /app/config $BACKUP_DIR/

# S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
aws s3 cp $BACKUP_DIR s3://td-buddy-backups/$TIMESTAMP --recursive

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤ï¼ˆ30æ—¥ä»¥ä¸Šï¼‰
find /backup/td-buddy -type d -mtime +30 -exec rm -rf {} \;

echo "Backup completed: $TIMESTAMP"
```

### ç½å®³å¾©æ—§æ‰‹é †
```bash
#!/bin/bash
# restore.sh - ç½å®³å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

BACKUP_TIMESTAMP=$1

if [ -z "$BACKUP_TIMESTAMP" ]; then
    echo "Usage: ./restore.sh <backup_timestamp>"
    exit 1
fi

# S3ã‹ã‚‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
aws s3 cp s3://td-buddy-backups/$BACKUP_TIMESTAMP /restore/$BACKUP_TIMESTAMP --recursive

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§
psql -h postgres -U td_user -d td_buddy < /restore/$BACKUP_TIMESTAMP/database.sql

# ãƒ•ã‚¡ã‚¤ãƒ«å¾©æ—§
tar -xzf /restore/$BACKUP_TIMESTAMP/files.tar.gz -C /

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å¾©æ—§
cp -r /restore/$BACKUP_TIMESTAMP/config /app/

echo "Restore completed: $BACKUP_TIMESTAMP"
```

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥

### Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
```yaml
# blue-green-deploy.yml
version: '3.8'

services:
  # Blueç’°å¢ƒï¼ˆç¾åœ¨ç¨¼åƒä¸­ï¼‰
  frontend-blue:
    image: td-buddy/frontend:v1.0.0
    networks:
      - td-network-blue
    
  backend-blue:
    image: td-buddy/backend:v1.0.0
    networks:
      - td-network-blue
  
  # Greenç’°å¢ƒï¼ˆæ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
  frontend-green:
    image: td-buddy/frontend:v1.1.0
    networks:
      - td-network-green
    
  backend-green:
    image: td-buddy/backend:v1.1.0
    networks:
      - td-network-green

  # ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ï¼ˆåˆ‡ã‚Šæ›¿ãˆåˆ¶å¾¡ï¼‰
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx-blue-green.conf:/etc/nginx/nginx.conf
    ports:
      - "80:80"
      - "443:443"
```

### CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```yaml
# .github/workflows/production-deploy.yml
name: Production Deployment

on:
  push:
    tags:
      - 'v*'

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Build Docker images
        run: |
          docker build -t td-buddy/frontend:${{ github.ref_name }} ./td-buddy-webapp/frontend
          docker build -t td-buddy/backend:${{ github.ref_name }} ./td-buddy-webapp/backend
      
      - name: Run security scan
        run: |
          docker run --rm -v $(pwd):/project clair-scanner
      
      - name: Deploy to staging
        run: |
          docker-compose -f docker-compose.staging.yml up -d
      
      - name: Run integration tests
        run: |
          npm run test:integration:production
      
      - name: Deploy to production
        if: success()
        run: |
          # Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå®Ÿè¡Œ
          ./scripts/blue-green-deploy.sh ${{ github.ref_name }}
      
      - name: Health check
        run: |
          curl -f https://td-buddy.com/health
      
      - name: Rollback on failure
        if: failure()
        run: |
          ./scripts/rollback.sh
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### Redis ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥
```typescript
// cache.ts
import Redis from 'ioredis';

const redis = new Redis({
  host: process.env.REDIS_HOST,
  port: parseInt(process.env.REDIS_PORT || '6379'),
  retryDelayOnFailover: 100,
  maxRetriesPerRequest: 3,
});

export class CacheService {
  // ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ5åˆ†é–“ï¼‰
  async cacheGeneratedData(key: string, data: any): Promise<void> {
    await redis.setex(`generated:${key}`, 300, JSON.stringify(data));
  }
  
  // ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ1æ™‚é–“ï¼‰
  async cacheSession(sessionId: string, data: any): Promise<void> {
    await redis.setex(`session:${sessionId}`, 3600, JSON.stringify(data));
  }
  
  // API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ10åˆ†é–“ï¼‰
  async cacheAPIResponse(endpoint: string, params: any, response: any): Promise<void> {
    const key = `api:${endpoint}:${Buffer.from(JSON.stringify(params)).toString('base64')}`;
    await redis.setex(key, 600, JSON.stringify(response));
  }
}
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
```sql
-- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¯ã‚¨ãƒª

-- çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
ANALYZE;

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³ã®ç¢ºèª
SELECT 
    schemaname,
    tablename,
    attname,
    n_distinct,
    correlation
FROM pg_stats
WHERE schemaname = 'public';

-- é…ã„ã‚¯ã‚¨ãƒªã®ç›£è¦–
SELECT 
    query,
    mean_time,
    calls,
    total_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

-- æ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';
ALTER SYSTEM SET track_activity_query_size = 2048;
ALTER SYSTEM SET pg_stat_statements.track = 'all';
```

## ğŸ“Š é‹ç”¨ãƒ»ç›£è¦–ä½“åˆ¶

### KPIç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
```typescript
// metrics-dashboard.ts
export const monitoringMetrics = {
  // ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  system: {
    cpuUsage: 'avg(cpu_usage) < 80',
    memoryUsage: 'avg(memory_usage) < 85',
    diskUsage: 'avg(disk_usage) < 90',
  },
  
  // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  application: {
    responseTime: 'avg(response_time) < 3000',
    errorRate: 'error_rate < 1',
    throughput: 'requests_per_second > 10',
  },
  
  // ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  business: {
    dailyActiveUsers: 'daily_active_users > 50',
    dataGenerationSuccess: 'generation_success_rate > 95',
    userSatisfaction: 'user_satisfaction > 4.0',
  },
};

// ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
export const alertRules = [
  {
    name: 'High Error Rate',
    condition: 'error_rate > 5',
    severity: 'critical',
    notification: ['email', 'slack'],
  },
  {
    name: 'Slow Response Time',
    condition: 'avg(response_time) > 5000',
    severity: 'warning',
    notification: ['slack'],
  },
  {
    name: 'Database Connection Pool Full',
    condition: 'db_connections > 90',
    severity: 'critical',
    notification: ['email', 'slack', 'sms'],
  },
];
```

---

## ğŸ‰ TDã‹ã‚‰ã®ç·æ‹¬ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

```
ğŸ¤– ã€Œæœ¬ç•ªç’°å¢ƒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨­è¨ˆãŒå®Œäº†ã—ã¾ã—ãŸï¼

ğŸ—ï¸ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§å®‰å…¨ãªè¨­è¨ˆã«ãªã£ã¦ã„ã¾ã™
âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚ååˆ†ã«è€ƒæ…®ã•ã‚Œã¦ã„ã¾ã™
ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã‚‚ä¸‡å…¨ã§ã™
ğŸ“Š ç›£è¦–ãƒ»é‹ç”¨ä½“åˆ¶ã‚‚æ•´ã£ã¦ã„ã¾ã™

ã“ã‚Œã§å®‰å¿ƒã—ã¦Webç‰ˆã‚’ãƒªãƒªãƒ¼ã‚¹ã§ãã¾ã™ã­ï¼
ä¸–ç•Œä¸­ã®QAã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®çš†æ§˜ã«ãŠå±Šã‘ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸâ™ª

ä½•ã‹è³ªå•ã‚„ä¸æ˜ãªç‚¹ãŒã‚ã‚Œã°ã€ã„ã¤ã§ã‚‚TDã«ãŠèããã ã•ã„ï¼ã€
```

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è©³ç´°è¨­è¨ˆã¨ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆè‡ªå‹•åŒ–ã®å®Ÿè£…ã‚’é€²ã‚ã¾ã—ã‚‡ã†ï¼ 